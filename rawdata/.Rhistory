model <- lm(log(sample.reads+0.5)~sample.time)
predictions <- (exp(predict(model,data.frame("sample.time"=0:200),interval = "confidence")))-0.5
plot(sample.time,sample.reads,type="n")
polygon(x = c(0:200, 200:0),
y = c(predictions[,3],rev(predictions[,2])),
col =  adjustcolor(colours, alpha.f = 0.30), border = NA)
lines(0:200,predictions[,1],lwd=3,col=colours)
#points(sample.time,sample.reads,pch=sample.tank,cex=1)
text(sample.time,sample.reads,labels=sample.tank,cex=1)
legend("topright",paste("reads=",modelData2$Reads[modelData2$Species==species]),bty="n",cex=0.9)
colours <- colours + 1
}
for (species in unique(spp)){
sample.reads <- trSpp$reads[spp==species]
sample.time <- time[spp==species]
sample.tank <- as.factor(tank[spp==species])
model <- lm(log(sample.reads+0.5)~sample.time*sample.tank)
print(species)
print(summary(model))
}
dev.off()
pdf("figures/Figure2/PerTankEffects.pdf",width=8,height=5)
par(mfrow=c(2,4))
par(mar=c(2.0, 2.0, 1.0, 1.0))
colours <- 1
for (species in modelData2$Species){
sample.reads <- trSpp$reads[spp==species]
sample.time <- time[spp==species]
sample.tank <- tank[spp==species]
model <- lm(log(sample.reads+0.5)~sample.time)
predictions <- (exp(predict(model,data.frame("sample.time"=0:200),interval = "confidence")))-0.5
plot(sample.time,sample.reads,type="n")
polygon(x = c(0:200, 200:0),
y = c(predictions[,3],rev(predictions[,2])),
col =  adjustcolor(colours, alpha.f = 0.30), border = NA)
lines(0:200,predictions[,1],lwd=3,col=colours)
#points(sample.time,sample.reads,pch=sample.tank,cex=1)
text(sample.time,sample.reads,labels=sample.tank,cex=1)
legend("topright",paste("reads=",modelData2$Reads[modelData2$Species==species]),bty="n",cex=0.9)
colours <- colours + 1
}
dev.off()
#now by number of tanks with positive detection
trSppBinary <- trSpp
trSppBinary$reads[trSppBinary$reads>0] <- 1
trSppBinary <- aggregate(trSppBinary$reads~trSppBinary$times+trSppBinary$spp,FUN=sum)
colnames(trSppBinary) <- c("times","spp","Nd")
View(trSppBinary)
trSppBinary <- aggregate(trSppBinary$reads~trSppBinary$times,FUN=sum)
#now by number of tanks with positive detection
trSppBinary <- trSpp
trSppBinary$reads[trSppBinary$reads>0] <- 1
trSppBinary <- aggregate(trSppBinary$reads~trSppBinary$times,FUN=sum)
View(trSppBinary)
#now by number of tanks with positive detection
trSppBinary <- trSpp
trSppBinary$reads[trSppBinary$reads>0] <- 1
trSppBinary.summed <- aggregate(trSppBinary$reads~trSppBinary$times,FUN=sum)
trSppBinary <- aggregate(trSppBinary$reads~trSppBinary$times+trSppBinary$spp,FUN=sum)
colnames(trSppBinary) <- c("times","spp","Nd")
par(mfrow=c(3,4))
par(mar=c(2.0, 2.0, 1.0, 1.0))
colours <- 1
for (species in unique(spp)[order(speciesReads,decreasing = T)]){
print(species)
sample.text <- metadatSpp$FinalID[match(species,metadatSpp$altID)]
sample.Nd <- trSppBinary$Nd[trSppBinary$spp==species]
sample.time <- trSppBinary$times[trSppBinary$spp==species]
plot(sample.time,sample.Nd,pch=16,ylim=c(0,4.2),col=colours,cex=1.2)
legend("topright",legend=sample.text,text.font = c(3),bty="n",cex=0.9)
colours <- colours +1
}
##################################
###Script 1 - Analysis###
####====0.0 Packages====####
library(data.table)
library(metabarTOAD)
library(vegan)
library(dplyr)
library(tidyr)
library(RColorBrewer)
library(ggplot2)
library(drc)
library(aomisc)
library(nlstools)
####====0.1 Data Import====####
rData <- read.csv("cleaned/Rarefied.clean.csv",row.names = 1)
rSpp <- read.csv("cleaned/RarefySppObservations.csv",row.names = 1)
rTaxa <- read.csv("taxonomy/Rarefied.clean.taxonomy.csv",row.names = 1)
metadat <- read.csv("metadata.csv")
metadatSpp <- read.csv("rawdata/SpikedMetazoans.csv")
times <- metadat$Hours[match(gsub("S","",colnames(rData)),metadat$ID)]
####====1.0 Entire Dataset Analysis====####
#OTUs over time
pdf("figures/Figure1/WholComm1.pdf",width=8,height=4)
par(mar=c(4.1, 4.1, 1.5, 1.5), mfrow=c(1,2))
#OTUs over time w/ nonlinear modeling
ASVrich <- colSums(rData != 0)
ASVwmod <- drm(ASVrich ~ times , fct =W1.4 ())
predictions <- predict(ASVwmod,data.frame("times"=0:200),interval = "confidence")
plot(times,ASVrich,type="n",xlab="Time (h)",ylab="ASV Richness")
polygon(x = c(0:200, 200:0),
y = c(predictions[,3],rev(predictions[,2])),
col =  adjustcolor("red", alpha.f = 0.10), border = NA)
lines(0:200,predictions[,1],lwd=3,col="red")
points(times,ASVrich,pch=16,col="black")
#Exponential Model
#ExpMod <- lm(log(ASVrich) ~ times)
#predictions <- exp(predict(ExpMod,data.frame("times"=0:200),interval = "confidence"))
#nls exponential
#ExpMod.2 <- nls(ASVrich ~ SSasymp(times, yf, y0, log_alpha))
#predictions <- exp(predict(ExpMod.2,data.frame("times"=0:200),interval = "confidence"))
#nMDS plot
MDSCOI <- metaMDS(vegdist(t(rData),distance = "jaccard",binary = TRUE))
MDSCOIdat <-as.data.frame(MDSCOI$points)
plot(MDSCOIdat,type="n")
points(MDSCOIdat$MDS1,MDSCOIdat$MDS2,pch=16,col="darkgrey")
timefactor <- as.factor(gsub("S[1-4].","",rownames(MDSCOIdat)))
surfout<- ordisurf(MDSCOI,metadat$Hours[match(gsub("S","",colnames(rData)),metadat$ID)],method="REML",add = TRUE,col="red",lty=2,lwd=2)
text(unlist(aggregate(MDSCOIdat$MDS1~timefactor,FUN=mean)[2]),
unlist(aggregate(MDSCOIdat$MDS2~timefactor,FUN=mean)[2]),
labels=levels(timefactor))
dev.off()
#Statistics
#4 param weibull model defined as follows
#b - curve steepness
#c - ASV lower limit
#d - ASV initial richness
#e - hours for inflection
summary(ASVwmod)
modelFit(ASVwmod)
#test a null by randomizing the order of samples to get an idea of a non-significant result
ASVwmod.null <- drm(ASVrich[sample(1:36,36)] ~ times , fct =W1.4 ())
test <- summary(ASVwmod.null)
#ASVwmod <- nls(ASVrich ~ times )
#selfStart(ASVrich ~ times)
#Time explains nMDS differences
envfit(MDSCOI,times)
####====2.0 Species Analysis====####
palette(rev(brewer.pal(12, "Set3")))
#Spp detection
#first by number of reads
#muck the data about
trSpp <- as.data.frame(t(rSpp))
trSpp <- gather(trSpp,key="spp",value="reads")
trSpp$times <- rep(times,dim(rSpp)[1])
trSpp$tank <-rep(c(rep(1,9),rep(2,9),rep(3,9),rep(4,9)),dim(rSpp)[1])
spp <- trSpp$spp
time <- trSpp$times
tank <- trSpp$tank
times <- trSpp$times[trSpp$spp==spp]
Rmax <- max(trSpp$reads)
#GGplot of raw data
pdf("figures/trial/SppReadsSep.pdf",width=7,height=5)
par(mar=c(4.1, 4.1, 1.5, 2.0), mfrow=c(1,1))
ggplot(trSpp, aes(times,reads)) + geom_point() + facet_wrap(vars(spp),scales="free_y")
#+ geom_smooth(method="lm", formula= (log(y+0.95) ~ x))
dev.off()
#Create a dataframe to collect data about models
modelData <- data.frame("Species"=unique(spp),
"Reads"=unique(spp),
"logL.R2"=rep(NA,length(unique(spp))),
"logL.p"=rep(NA,length(unique(spp))),
"logL.AIC"=rep(NA,length(unique(spp))),
"logL.AIC.2"=rep(NA,length(unique(spp))),
"logL.k"=rep(NA,length(unique(spp))),
"logL.95upr"=rep(NA,length(unique(spp))),
"logL.95lwr"=rep(NA,length(unique(spp))))
#Plot & model output showing poor fit of natural log linear model
# See https://stats.stackexchange.com/questions/48714/prerequisites-for-aic-model-comparison
# to correct AIC when log transforming data
sink("rawdata/loglinearmodelout.txt")
for (species in unique(spp)){
sample.reads <- trSpp$reads[spp==species]
sample.time <- time[spp==species]
model <- lm(log(sample.reads+0.5)~sample.time)
print(species)
print(summary(model))
modelData[modelData$Species==species,2] <- sum(sample.reads)
modelData[modelData$Species==species,3] <- summary(model)$adj.r.squared
modelData[modelData$Species==species,4] <- summary(model)$coefficients[2,4]
modelData[modelData$Species==species,5] <- AIC(model)
modelData[modelData$Species==species,6] <- AIC(model)+2*sum(log(sample.reads+0.5))
modelData[modelData$Species==species,7] <- model$coefficients[2]
modelData[modelData$Species==species,8] <- confint(model, level=0.95)[2,1]
modelData[modelData$Species==species,9] <- confint(model, level=0.95)[2,2]
}
sink()
modelData2 <- modelData[modelData$logL.p<0.05,]
modelData2 <- modelData2[order(as.numeric(modelData2$Reads),decreasing = TRUE),]
pdf("figures/Figure2/Spp.pdf",width=7,height=3.5)
par(mfrow=c(2,4))
par(mar=c(2.0, 2.0, 1.0, 1.0))
colours <- 1
for (species in modelData2$Species){
sample.reads <- trSpp$reads[spp==species]
sample.time <- time[spp==species]
model <- lm(log(sample.reads+0.5)~sample.time)
predictions <- (exp(predict(model,data.frame("sample.time"=0:200),interval = "confidence")))-0.5
plot(sample.time,sample.reads,type="n")
polygon(x = c(0:200, 200:0),
y = c(predictions[,3],rev(predictions[,2])),
col =  adjustcolor(colours, alpha.f = 0.30), border = NA)
lines(0:200,predictions[,1],lwd=3,col=colours)
points(sample.time,sample.reads,pch=16,cex=1)
legend("topright",paste("reads=",modelData2$Reads[modelData2$Species==species]),bty="n",cex=0.9)
colours <- colours + 1
}
dev.off()
##Attempt @ tank effects following reviewers comments
pdf("figures/Figure2/PerTankEffects.pdf",width=8,height=5)
par(mfrow=c(2,4))
par(mar=c(2.0, 2.0, 1.0, 1.0))
colours <- 1
for (species in modelData2$Species){
sample.reads <- trSpp$reads[spp==species]
sample.time <- time[spp==species]
sample.tank <- tank[spp==species]
model <- lm(log(sample.reads+0.5)~sample.time)
predictions <- (exp(predict(model,data.frame("sample.time"=0:200),interval = "confidence")))-0.5
plot(sample.time,sample.reads,type="n")
polygon(x = c(0:200, 200:0),
y = c(predictions[,3],rev(predictions[,2])),
col =  adjustcolor(colours, alpha.f = 0.30), border = NA)
lines(0:200,predictions[,1],lwd=3,col=colours)
#points(sample.time,sample.reads,pch=sample.tank,cex=1)
text(sample.time,sample.reads,labels=sample.tank,cex=1)
legend("topright",paste("reads=",modelData2$Reads[modelData2$Species==species]),bty="n",cex=0.9)
colours <- colours + 1
}
dev.off()
for (species in unique(spp)){
sample.reads <- trSpp$reads[spp==species]
sample.time <- time[spp==species]
sample.tank <- as.factor(tank[spp==species])
model <- lm(log(sample.reads+0.5)~sample.time+sample.tank)
print(species)
print(summary(model))
}
#Non linear exponential decay model
#First we set up the model and save some data
sink("rawdata/non-linearmodelout2(nls).txt")
#We are going to grow the list dynamically, this is bad luck.
speciesReads <- c()
speciesK <- c()
speciesKerrUpr <- c()
speciesKerrLwr <- c()
speciesR2 <- c()
speciesAIC <- c()
for (species in unique(rownames(rSpp))){
print(species)
sample.reads <- trSpp$reads[spp==species]
sample.time <- time[spp==species]
model <- nls(sample.reads ~ SSasymp(sample.time, yf, y0, log_alpha))
print(summary(model))
#Extract read count
runningReads <- sum(sample.reads)
names(runningReads) <- species
speciesReads <- c(speciesReads,runningReads)
#Extract K
runningK <- exp(coef(model)[3])
names(runningK) <- species
speciesK <- c(speciesK,runningK)
#Extract K 95% cofInt
runningKerrUpr <- round(exp(confint2(model)[3,1]),7)
runningKerrLwr <- round(exp(confint2(model)[3,2]),7)
names(runningKerrUpr) <- species
names(runningKerrLwr) <- species
speciesKerrUpr <- c(speciesKerrUpr,runningKerrUpr)
speciesKerrLwr <- c(speciesKerrLwr,runningKerrLwr)
#Extract R2
RSS.p <- sum(residuals(model)^2) # Residual sum of squares
TSS <- sum((sample.reads  - mean(sample.reads ))^2) # Total sum of squares
runningR <- (1 - (RSS.p/TSS))  # R-squared measure
names(runningR) <- species
speciesR2 <- c(speciesR2,runningR)
runningAIC <- AIC(model)
names(runningAIC) <- species
speciesAIC <- c(speciesAIC,runningAIC)
}
sink()
modelData$reads <- speciesReads
modelData$nls.k <- speciesK
modelData$nls.k.95upr <- speciesKerrLwr
modelData$nls.k.95lwr <- speciesKerrUpr
modelData$nlsR2 <- speciesR2
modelData$nls.AIC <- speciesAIC
modelData <- modelData[order(modelData$reads,decreasing = T),]
modelDataOut <- modelData[,1:2]
modelDataOut$Species <- metadatSpp$FinalID[match(modelDataOut$Species,metadatSpp$altID)]
modelDataOut <- cbind(modelDataOut,modelData[,c(3,4,7,8,9,6,14,11,12,13,15)])
write.csv(modelDataOut,"model.outputs.csv")
##PLot of data
pdf("figures/Figure2/Decay.pdf",width = 2,height=5)
par(mfrow=c(1,1),mar=c(2.0, 1.0, 1.0, 2.0))
plot(1:8,sqrt(modelData2$logL.k^2),
ylim=c(sqrt(min(modelData2$logL.95lwr^2)),sqrt(max(modelData2$logL.95upr^2))),
xlim=c(0.5,8.5),
col=1:8,pch=3,cex=1,xaxt='n',yaxt="n")
axis(4)
mtext(text="Decay Model k Estimate (hr-1)",side=4,line=3)
for (sppN in 1:8){
lines(c(sppN,sppN),c(sqrt(modelData2$logL.95upr[sppN]^2),sqrt(modelData2$logL.95lwr[sppN]^2)),col=sppN,lwd=3)
}
dev.off()
#Now lets plot the relationship
pdf("figures/Figure2/Figure2.supp.pdf",width=7,height=5)
par(mfrow=c(3,4))
par(mar=c(2.0, 2.0, 1.0, 1.0))
colours <- 1
for (species in unique(spp)[order(speciesReads,decreasing = T)]){
print(species)
sample.text <- metadatSpp$FinalID[match(species,metadatSpp$altID)]
sample.reads <- trSpp$reads[spp==species]
sample.time <- time[spp==species]
plot(sample.time,sample.reads,pch=16)
model <- nls(sample.reads ~ SSasymp(sample.time, yf, y0, log_alpha))
predictions <- predict(model,data.frame("sample.time"=0:200),interval = "confidence")
lines(0:200,predictions,lwd=3,col=colours)
points(sample.time,sample.reads,pch=16,cex=1)
legend("topright",legend=c(sample.text,paste0(" reads=",sum(sample.reads))),text.font = c(3,1),bty="n",cex=0.9)
colours <- colours +1
}
dev.off()
#now by number of tanks with positive detection
trSppBinary <- trSpp
trSppBinary$reads[trSppBinary$reads>0] <- 1
trSppBinary.summed <- aggregate(trSppBinary$reads~trSppBinary$times,FUN=sum)
trSppBinary <- aggregate(trSppBinary$reads~trSppBinary$times+trSppBinary$spp,FUN=sum)
colnames(trSppBinary) <- c("times","spp","Nd")
par(mfrow=c(3,4))
par(mar=c(2.0, 2.0, 1.0, 1.0))
colours <- 1
for (species in unique(spp)[order(speciesReads,decreasing = T)]){
print(species)
sample.text <- metadatSpp$FinalID[match(species,metadatSpp$altID)]
sample.Nd <- trSppBinary$Nd[trSppBinary$spp==species]
sample.time <- trSppBinary$times[trSppBinary$spp==species]
plot(sample.time,sample.Nd,pch=16,ylim=c(0,4.2),col=colours,cex=1.2)
legend("topright",legend=sample.text,text.font = c(3),bty="n",cex=0.9)
colours <- colours +1
}
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`)
par(mfrow=c(1,1))
par(mar=c(2.0, 2.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`)
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`,pch=16)
par(mar=c(3.0, 3.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`,pch=16)
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`/4,trSppBinary.summed$`trSppBinary$reads`,pch=16,
xlab="Time (hrs)",
ylab="Number of species")
trSppBinary.summed$`trSppBinary$times`/4
trSppBinary.summed$`trSppBinary$times`
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`/4,pch=16,
xlab="Time (hrs)",
ylab="Number of species")
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`/4,pch=16,
xlab="Time (hrs)",
ylab="Average number of species detected across tanks")
pdf("figures/SppNdsummed.pdf",width=7,height=5)
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`/4,pch=16,
xlab="Time (hrs)",
ylab="Average number of species detected across tanks")
dev.off()
pdf("figures/SppNdsummed.pdf",width=4,height=2.5)
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`/4,pch=16,
xlab="Time (hrs)",
ylab="Average number of species detected across tanks")
dev.off()
pdf("figures/SppNdsummed.pdf",width=5,height=3)
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`/4,pch=16,
xlab="Time (hrs)",
ylab="Average number of species detected across tanks")
dev.off()
pdf("figures/SppNdsummed.pdf",width=5,height=3.5)
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`/4,pch=16,
xlab="Time (hrs)",
ylab="Average number of species detected across tanks")
dev.off()
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`/4,pch=16,
xlab="Time (hrs)",
ylab="Average N detections")
pdf("figures/SppNdsummed.pdf",width=5,height=3.5)
par(mfrow=c(1,1))
par(mar=c(4.0, 4.0, 1.0, 1.0))
plot(trSppBinary.summed$`trSppBinary$times`,trSppBinary.summed$`trSppBinary$reads`/4,pch=16,
xlab="Time (hrs)",
ylab="Average N detections")
dev.off()
library(data.table)
library(metabarTOAD)
library(vegan)
library(dplyr)
library(seqinr)
####====0.1 Parameters====####
#Set some variables
minreads <- 2
items <- NULL
#Set the seed
set.seed("123456")
#Read in metadata
metadat<-read.csv("metadata.csv")
####====0.2 Taxonomy ====####
##taxonomy
#Tax <- fread(file = "taxonomy/YiMTB.tax.txt",sep="\t")
#names(Tax) <- c("OTUID","qlen","slen","qcov","qcovhsp","sseqid","bitscore","score","evalue","pctid","qstart","qend","start","send","staxid","sscinames")
#write.table(Tax,"taxonomy/RawTaxonomy.txt",row.names=FALSE,sep="\t", quote = FALSE)
#Assignments <- ParseTaxonomy(blastoutput = "taxonomy/RawTaxonomy.txt",lineages = "taxonomy/lineages-2019-08-14.csv.gz",lwrcovpct=80)
#write.table(Assignments,file="taxonomy/Parsedtax.csv",row.names=FALSE,sep=",", quote = FALSE)
Assignments <- read.csv("taxonomy/Parsedtax.csv")
####====0.3 OTU Table Cleaning  ====####
setwd("rawdata/")
rawdat <-read.csv(file="AllSamples.lulu.dada2.csv")
metadat$ID <- gsub("X","S",make.names(metadat$ID))
colnames(rawdat) <- gsub("X","S",colnames(rawdat))
#Separate controls and samples
samples <- rawdat[colnames(rawdat) %in% metadat$ID[metadat$Type=="sample" | metadat$Type=="control" ]]
check <- rawdat[colnames(rawdat) %in% metadat$ID[metadat$Type=="control.check"]]
controls <-  rawdat[colnames(rawdat) %in% metadat$ID[metadat$Type=="control.n"]]
#Filter 1 - minimum number of reads for any ID
samples[samples< minreads] <- 0
samples <- samples[rowSums(samples) > 0,]
#Filter 2 - within samples OTU must appear in more than one sample (this works because there are lots of reps per site and sample)
filtersam <- samples
filtersam[filtersam>0 ] <- 1
filtersam <-filtersam[rowSums(filtersam) > 1,]
samples <- samples[rownames(samples) %in% rownames(filtersam),]
#Filter 3 -Make the maximum umber of reads for each OTU in the contam 100
controlsCONTAM <- controls[rowSums(controls) > 0,]
for (contamOTU in 1:length(controlsCONTAM[,1])){
loopOTU <- row.names(controlsCONTAM[contamOTU,])
loopMax <- 100
if (any(is.na(samples[loopOTU,]))){next}
samples[loopOTU,samples[loopOTU,]<loopMax] <- 0
print(paste("Cleaning contaminants",contamOTU))
}
#now we add some taxonomy
##for the main samples
assigned <- data.frame(matrix(nrow= dim(samples)[1],ncol=10))
rownames(assigned) <- rownames(samples)
colnames(assigned) <- colnames(Assignments)
temp <- as.data.frame(apply(Assignments,2, as.character),stringsAsFactors=FALSE)
for (row in 1:dim(samples)[1]){
if(!rownames(samples)[row] %in% Assignments$OTU){
next()}
assigned[rownames(assigned)[row],] <-  temp[na.omit(match(rownames(assigned)[row],as.character(temp$OTU))),]
}
assigned <- cbind(samples,assigned)
##for the check samples
assigned.c <- data.frame(matrix(nrow= dim(check)[1],ncol=10))
rownames(assigned.c) <- rownames(check)
colnames(assigned.c) <- colnames(Assignments)
temp <- as.data.frame(apply(Assignments,2, as.character),stringsAsFactors=FALSE)
for (row in 1:dim(check)[1]){
if(!rownames(check)[row] %in% Assignments$OTU){
next()}
assigned.c[rownames(assigned.c)[row],] <-  temp[na.omit(match(rownames(assigned.c)[row],as.character(temp$OTU))),]
}
assigned.c <- cbind(check,assigned.c)
#Now we write out the cleaned data
write.csv(assigned,file="../cleaned/cleaned.dada2.data.csv")
write.csv(assigned.c,file="../cleaned/checkdata.csv")
####====0.4 Cross Contam Test  ====####
#1.Identify OTUs unique to the 4 tanks from the natural site at time 0 compared to the artificial sites
contamDat <- assigned[c("S1.T0","S2.T0","S3.T0","S4.T0","S5.T0","S6.T0","S7.T0","S8.T0")]
View(contamDat)
#contamDat <- assigned[c("C1","C2","C3","C4","C5","C6","C7","C8")]
contamDat[contamDat>0] <- 1
contamDat <- cbind(rowSums(contamDat[,1:4]),rowSums(contamDat[,5:8]))
contamDat <- as.data.frame(contamDat)
View(contamDat)
uniqueOTus <- rownames(contamDat)[ifelse(contamDat$V1==0 & contamDat$V2==4,TRUE,FALSE)]
#2.Create a dataset containing only these OTUs
contamOTUdat <- assigned[match(uniqueOTus,rownames(assigned)),]
View(contamOTUdat)
contamOTUdatexp <- contamOTUdat[,grep("S[1-4].T[1-9]",colnames(contamOTUdat))]
View(contamOTUdatexp)
highOTU <- na.omit(assigned$OTU[assigned$assignmentQual=="High"])
lowOTU <- na.omit(assigned$OTU[assigned$assignmentQual=="Low"])
highcontam <- contamOTUdatexp[na.omit(match(highOTU,rownames(contamOTUdatexp))),]
lowcontam <- contamOTUdatexp[na.omit(match(lowOTU,rownames(contamOTUdatexp))),]
View(highcontam)
expSamples <- assigned[,grep("S[1-4].T[1-9]",colnames(assigned))]
readsperSample <- colSums(expSamples)
highreadsperSample <- colSums(highcontam)
lowreadsperSample <- colSums(lowcontam)
mean(highreadsperSample / readsperSample *100)
taxaContam <- Assignments[match(rownames(highcontam),Assignments$OTU),]
test <- cbind(highcontam,Assignments[match(rownames(highcontam),Assignments$OTU),])
#descriptive statistics for reporting
highreadsperSample
mean(highreadsperSample)
sd(highreadsperSample)
mean(highreadsperSample / readsperSample *100)
sd(highreadsperSample / readsperSample *100)
